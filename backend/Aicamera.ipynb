{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CROWDPULSE\n"
      ],
      "metadata": {
        "id": "N33p-ptk3yqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# üîê Twilio credentials (PLACEHOLDERS ONLY)\n",
        "os.environ[\"TWILIO_ACCOUNT_SID\"] = \"TWILIO_ACCOUNT_SID_HERE\"\n",
        "os.environ[\"TWILIO_AUTH_TOKEN\"]  = \"TWILIO_AUTH_TOKEN_HERE\"\n",
        "os.environ[\"TWILIO_NUMBER\"]      = \"TWILIO_PHONE_NUMBER_HERE\"\n",
        "\n",
        "# üîê Groq LLM\n",
        "os.environ[\"GROQ_API_KEY\"] = \"GROQ_API_KEY_HERE\"\n",
        "\n",
        "# üîê Ngrok\n",
        "os.environ[\"NGROK_AUTH_TOKEN\"] = \"NGROK_AUTH_TOKEN_HERE\"\n",
        "\n",
        "print(\"üîê Placeholder keys loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el_DkPhV7LJM",
        "outputId": "ec6b0bb6-28cc-4299-b838-70aa524751f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîê Placeholder keys loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from collections import deque\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Build CSRNet\n",
        "class CSRNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CSRNet, self).__init__()\n",
        "        vgg = models.vgg16(weights='DEFAULT')\n",
        "        self.frontend = nn.Sequential(*list(vgg.features.children())[:23])\n",
        "        self.backend = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, 3, padding=2, dilation=2), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, padding=2, dilation=2), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 3, padding=2, dilation=2), nn.ReLU(),\n",
        "            nn.Conv2d(512, 256, 3, padding=2, dilation=2), nn.ReLU(),\n",
        "            nn.Conv2d(256, 128, 3, padding=2, dilation=2), nn.ReLU(),\n",
        "            nn.Conv2d(128, 64, 3, padding=2, dilation=2), nn.ReLU(),\n",
        "        )\n",
        "        self.output_layer = nn.Conv2d(64, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.frontend(x)\n",
        "        x = self.backend(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "model = CSRNet()\n",
        "print(\"Model built\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt52NCze31J4",
        "outputId": "c27586e1-efc0-4282-8c96-19e3a0ea84fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model built\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/rootstrap-org/crowd-counting/resolve/main/weights.pth -O csrnet_weights.pth\n",
        "\n",
        "checkpoint = torch.load('/content/csrnet_weights.pth', map_location='cpu')\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()\n",
        "print(\"Weights loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awi9W99p34Ak",
        "outputId": "3e60b3ab-6709-4882-91f5-5e888d866f70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-28 11:12:49--  https://huggingface.co/rootstrap-org/crowd-counting/resolve/main/weights.pth\n",
            "Resolving huggingface.co (huggingface.co)... 3.165.160.59, 3.165.160.11, 3.165.160.12, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.165.160.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/65a7044c293f73160dd702a4/950644f6b69af20d5cea617c94a6c18734cebcba84dac27bc73e9956c4151137?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27weights.pth%3B+filename%3D%22weights.pth%22%3B&Expires=1772280769&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcyMjgwNzY5fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjVhNzA0NGMyOTNmNzMxNjBkZDcwMmE0Lzk1MDY0NGY2YjY5YWYyMGQ1Y2VhNjE3Yzk0YTZjMTg3MzRjZWJjYmE4NGRhYzI3YmM3M2U5OTU2YzQxNTExMzdcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=gpZZ5v9RAA4sZcyE8II9uQVMIdqhdk15CZxum67cFD2fXfOHrlHIuHuiqym-g9tyL4sgaHqPzySOOCagT9lFOgu4a8%7EM9dSe8FHbugNG0rRoZFeBYFuxPn--sSS6JAjFXpxbl3tLOgiztHSJ4y1iWe-19047nrkpN8CXYZCKTqnT0ubFp5Hsh7zDfGG-4G%7EPzZu5ya-Qf3wZlKoweFhn2HV1gazrbcM5RSF3xX0eDN5HMW9NxxE%7EYBuxbxztM07INY8TkzTgmXaKJ607k9nIyy8f8aobfjbEVXGHa1SPEDVlNjUfVIRltHJ363QgWlS%7EaCr-DvWcxro81q30xMLmjA__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
            "--2026-02-28 11:12:49--  https://us.gcp.cdn.hf.co/xet-bridge-us/65a7044c293f73160dd702a4/950644f6b69af20d5cea617c94a6c18734cebcba84dac27bc73e9956c4151137?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27weights.pth%3B+filename%3D%22weights.pth%22%3B&Expires=1772280769&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcyMjgwNzY5fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjVhNzA0NGMyOTNmNzMxNjBkZDcwMmE0Lzk1MDY0NGY2YjY5YWYyMGQ1Y2VhNjE3Yzk0YTZjMTg3MzRjZWJjYmE4NGRhYzI3YmM3M2U5OTU2YzQxNTExMzdcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=gpZZ5v9RAA4sZcyE8II9uQVMIdqhdk15CZxum67cFD2fXfOHrlHIuHuiqym-g9tyL4sgaHqPzySOOCagT9lFOgu4a8%7EM9dSe8FHbugNG0rRoZFeBYFuxPn--sSS6JAjFXpxbl3tLOgiztHSJ4y1iWe-19047nrkpN8CXYZCKTqnT0ubFp5Hsh7zDfGG-4G%7EPzZu5ya-Qf3wZlKoweFhn2HV1gazrbcM5RSF3xX0eDN5HMW9NxxE%7EYBuxbxztM07INY8TkzTgmXaKJ607k9nIyy8f8aobfjbEVXGHa1SPEDVlNjUfVIRltHJ363QgWlS%7EaCr-DvWcxro81q30xMLmjA__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
            "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 35.219.133.190\n",
            "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|35.219.133.190|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65063231 (62M) [application/octet-stream]\n",
            "Saving to: ‚Äòcsrnet_weights.pth‚Äô\n",
            "\n",
            "csrnet_weights.pth  100%[===================>]  62.05M  46.2MB/s    in 1.3s    \n",
            "\n",
            "2026-02-28 11:12:50 (46.2 MB/s) - ‚Äòcsrnet_weights.pth‚Äô saved [65063231/65063231]\n",
            "\n",
            "Weights loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Zone history\n",
        "zone_history = {\n",
        "    \"Zone_A\": deque(maxlen=5),\n",
        "    \"Zone_B\": deque(maxlen=5),\n",
        "    \"Zone_C\": deque(maxlen=5),\n",
        "    \"Zone_D\": deque(maxlen=5)\n",
        "}\n",
        "\n",
        "def get_status(score):\n",
        "    if score > 200:\n",
        "        return \"CRITICAL\", (0, 0, 255)\n",
        "    elif score > 150:\n",
        "        return \"DANGER\",   (0, 0, 200)\n",
        "    elif score > 100:\n",
        "        return \"WARNING\",  (0, 165, 255)\n",
        "    elif score > 50:\n",
        "        return \"MONITOR\",  (0, 255, 255)\n",
        "    else:\n",
        "        return \"SAFE\",     (0, 255, 0)\n",
        "\n",
        "def predict_time_to_danger(history, threshold=200):\n",
        "    values = list(history)\n",
        "    if len(values) < 2:\n",
        "        return None\n",
        "    growth_rates = [values[i+1] - values[i] for i in range(len(values)-1)]\n",
        "    avg_growth = sum(growth_rates) / len(growth_rates)\n",
        "    if avg_growth <= 0:\n",
        "        return None\n",
        "    current = values[-1]\n",
        "    if current >= threshold:\n",
        "        return 0\n",
        "    return round((threshold - current) / avg_growth, 1)\n",
        "\n",
        "def process_frame(frame):\n",
        "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    img_tensor = transform(img).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "    density_map = output.squeeze().detach().numpy()\n",
        "    h, w = density_map.shape\n",
        "    zones_data = {\n",
        "        \"Zone_A\": float(density_map[0:h//2, 0:w//2].sum()),\n",
        "        \"Zone_B\": float(density_map[0:h//2, w//2:w].sum()),\n",
        "        \"Zone_C\": float(density_map[h//2:h, 0:w//2].sum()),\n",
        "        \"Zone_D\": float(density_map[h//2:h, w//2:w].sum())\n",
        "    }\n",
        "    for zone, score in zones_data.items():\n",
        "        zone_history[zone].append(score)\n",
        "    return zones_data\n",
        "\n",
        "def draw_zones_on_frame(frame, zones_data):\n",
        "    h, w = frame.shape[:2]\n",
        "    zone_coords = {\n",
        "        \"Zone_A\": (0, 0, w//2, h//2),\n",
        "        \"Zone_B\": (w//2, 0, w, h//2),\n",
        "        \"Zone_C\": (0, h//2, w//2, h),\n",
        "        \"Zone_D\": (w//2, h//2, w, h)\n",
        "    }\n",
        "    for zone, (x1, y1, x2, y2) in zone_coords.items():\n",
        "        score = zones_data[zone]\n",
        "        status, color = get_status(score)\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
        "        cv2.putText(frame, f\"{zone}: {status} ({score:.0f})\",\n",
        "                    (x1+10, y1+35), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.7, color, 2)\n",
        "    return frame\n",
        "\n",
        "def generate_alert_json(zone_history, zones_data):\n",
        "    output = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"total_count\": int(sum(zones_data.values())),\n",
        "        \"zones\": {},\n",
        "        \"active_alerts\": []\n",
        "    }\n",
        "    for zone, history in zone_history.items():\n",
        "        current = list(history)[-1] if history else 0\n",
        "        mins = predict_time_to_danger(history)\n",
        "        status, _ = get_status(current)\n",
        "        alert = status in [\"CRITICAL\", \"DANGER\", \"WARNING\"]\n",
        "        output[\"zones\"][zone] = {\n",
        "            \"current_count\": round(current, 1),\n",
        "            \"status\": status,\n",
        "            \"predicted_danger_in_mins\": mins,\n",
        "            \"alert\": alert\n",
        "        }\n",
        "        if alert:\n",
        "            output[\"active_alerts\"].append({\n",
        "                \"zone\": zone,\n",
        "                \"message\": f\"{zone} crowd at {status} level ‚Äî {f'danger in {mins} mins' if mins and mins > 0 else 'IMMEDIATE ACTION NEEDED'}\",\n",
        "                \"urgency\": status\n",
        "            })\n",
        "    return output\n",
        "\n",
        "print(\"All functions ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yeh_kcwD3-0X",
        "outputId": "105d42a2-84b2-432e-e508-9587380abc40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All functions ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print(\"Upload your crowd video\")\n",
        "uploaded_video = files.upload()\n",
        "video_path = list(uploaded_video.keys())[0]\n",
        "print(f\"Uploaded: {video_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "pwQlfyGA4BGu",
        "outputId": "07f58dba-b0cb-40cf-c3a9-3e869ba15582"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your crowd video\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-98071bac-981e-4ef8-b070-ccd785aa79f0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-98071bac-981e-4ef8-b070-ccd785aa79f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Shopping, People, Commerce, Mall, Many, Crowd, Walking   Free Stock video footage   YouTube_720p.mp4 to Shopping, People, Commerce, Mall, Many, Crowd, Walking   Free Stock video footage   YouTube_720p (1).mp4\n",
            "Uploaded: Shopping, People, Commerce, Mall, Many, Crowd, Walking   Free Stock video footage   YouTube_720p (1).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making phone call alerts"
      ],
      "metadata": {
        "id": "ax-eMgM17tBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install twilio\n",
        "print(\"Twilio installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imOIB2oG7sHS",
        "outputId": "32444dbb-6c9c-4d31-b41e-9a1c69a55ad6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: twilio in /usr/local/lib/python3.12/dist-packages (9.10.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from twilio) (2.32.4)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from twilio) (2.11.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.12/dist-packages (from twilio) (3.13.3)\n",
            "Requirement already satisfied: aiohttp-retry>=2.8.3 in /usr/local/lib/python3.12/dist-packages (from twilio) (2.9.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->twilio) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->twilio) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->twilio) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->twilio) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->twilio) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->twilio) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.4->twilio) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->twilio) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->twilio) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->twilio) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->twilio) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.8.4->twilio) (4.15.0)\n",
            "Twilio installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from twilio.rest import Client\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Read Twilio credentials from environment variables\n",
        "ACCOUNT_SID = os.getenv(\"TWILIO_ACCOUNT_SID\")\n",
        "AUTH_TOKEN  = os.getenv(\"TWILIO_AUTH_TOKEN\")\n",
        "TWILIO_NUMBER = os.getenv(\"TWILIO_NUMBER\")\n",
        "\n",
        "if not all([ACCOUNT_SID, AUTH_TOKEN, TWILIO_NUMBER]):\n",
        "    raise ValueError(\"‚ùå Twilio environment variables not set\")\n",
        "\n",
        "# Guard registry ‚Äî which guard covers which zone\n",
        "guards = {\n",
        "    \"Zone_A\": {\"name\": \"Bene\",  \"phone\": \"+919148910903\"},\n",
        "    \"Zone_B\": {\"name\": \"Rohi\",  \"phone\": \"+918754787789\"},\n",
        "    \"Zone_C\": {\"name\": \"Adi\",   \"phone\": \"+919148910903\"},\n",
        "    \"Zone_D\": {\"name\": \"Ezhil\", \"phone\": \"+919148910903\"}\n",
        "}\n",
        "\n",
        "# Initialize Twilio client\n",
        "client = Client(ACCOUNT_SID, AUTH_TOKEN)\n",
        "print(\"‚úÖ Twilio client ready\")\n",
        "print(f\"Guards registered: {len(guards)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbTwNWhx7xmt",
        "outputId": "2e063732-cbca-4621-fd5f-508c26cc6c9d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Twilio client ready\n",
            "Guards registered: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groq AI"
      ],
      "metadata": {
        "id": "xo36uWZP8Lqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q groq"
      ],
      "metadata": {
        "id": "ktYMIrx58LZ8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n",
        "\n",
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "# Read Groq API key from environment\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"‚ùå GROQ_API_KEY not set\")\n",
        "\n",
        "groq_client = Groq(api_key=GROQ_API_KEY)\n",
        "print(\"‚úÖ Groq client ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF8kmiP48728",
        "outputId": "3d1fd710-602f-4c7e-ea82-0fc4506ef22f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "‚úÖ Groq client ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run this to update model name\n",
        "def generate_alert_message(zone, guard_name, current_count, mins, safe_zone):\n",
        "    prompt = f\"\"\"\n",
        "    You are CrowdPulse, an AI safety system at a public event.\n",
        "    Generate a short, urgent voice alert message for a security guard.\n",
        "\n",
        "    Situation:\n",
        "    - Zone: {zone}\n",
        "    - Guard name: {guard_name}\n",
        "    - Current crowd count: {current_count}\n",
        "    - Minutes until critical: {mins}\n",
        "    - Nearest safe zone: {safe_zone}\n",
        "\n",
        "    Rules:\n",
        "    - Max 3 sentences\n",
        "    - Mention guard name, zone, time, and safe zone\n",
        "    - Urgent but clear tone\n",
        "    - No special characters\n",
        "    \"\"\"\n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def generate_incident_report(json_data):\n",
        "    prompt = f\"\"\"\n",
        "    You are CrowdPulse AI. Generate a professional incident report from this crowd data:\n",
        "    {json.dumps(json_data, indent=2)}\n",
        "\n",
        "    Include:\n",
        "    - Summary with exact crowd counts per zone\n",
        "    - Which zones were dangerous and their predicted_danger_in_mins value\n",
        "    - Example: \"Zone C had 133 people ‚Äî critical predicted in 10.6 minutes\"\n",
        "    - Actions taken\n",
        "    - Recommendations specific to these zones\n",
        "\n",
        "    Keep under 150 words. Use the exact numbers from the data.\n",
        "    \"\"\"\n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def generate_crowd_analysis(all_json_outputs):\n",
        "    prompt = f\"\"\"\n",
        "    You are CrowdPulse AI, an expert crowd safety analyst for Indian public events.\n",
        "    Analyze this real sensor data from a live event:\n",
        "    {json.dumps(all_json_outputs, indent=2)}\n",
        "\n",
        "    Give SPECIFIC, DATA-DRIVEN insights only. No generic advice.\n",
        "    Use the actual zone names, timestamps, and crowd counts from the data.\n",
        "\n",
        "    Format your response exactly like this:\n",
        "\n",
        "    PEAK CONGESTION:\n",
        "    [exact zone, exact time, exact count from data]\n",
        "\n",
        "    DANGER TIMELINE:\n",
        "    [list each zone alert with exact time it triggered and how long it lasted]\n",
        "\n",
        "    CROWD FLOW PATTERN:\n",
        "    [what actually happened zone by zone based on the numbers]\n",
        "\n",
        "    TOP 3 RECOMMENDATIONS FOR NEXT EVENT:\n",
        "    1. [specific to this venue's zones and what actually went wrong]\n",
        "    2. [specific gate/timing recommendation based on peak time observed]\n",
        "    3. [specific staffing recommendation based on which zones were problematic]\n",
        "\n",
        "    Use only data from the JSON. No assumptions. No generic statements.\n",
        "    Keep under 200 words.\n",
        "    \"\"\"\n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "jJF81Amp9HRH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_genai_alert_call(zone, guard_name, guard_phone, current_count, mins):\n",
        "\n",
        "    # Find nearest safe zone\n",
        "    safe_zones = {\"Zone_A\": \"Zone_B\", \"Zone_B\": \"Zone_A\",\n",
        "                  \"Zone_C\": \"Zone_D\", \"Zone_D\": \"Zone_C\"}\n",
        "    safe_zone = safe_zones.get(zone, \"nearest exit\")\n",
        "\n",
        "    # Generate AI message\n",
        "    ai_message = generate_alert_message(\n",
        "        zone=zone,\n",
        "        guard_name=guard_name,\n",
        "        current_count=current_count,\n",
        "        mins=mins,\n",
        "        safe_zone=safe_zone\n",
        "    )\n",
        "\n",
        "    print(f\"AI Generated Message: {ai_message}\")\n",
        "\n",
        "    # Fire voice call with AI message\n",
        "    twiml_message = f\"\"\"\n",
        "    <Response>\n",
        "        <Say voice=\"alice\" language=\"en-IN\">\n",
        "            {ai_message}\n",
        "        </Say>\n",
        "        <Pause length=\"1\"/>\n",
        "        <Say voice=\"alice\" language=\"en-IN\">\n",
        "            Repeating. {ai_message}\n",
        "        </Say>\n",
        "    </Response>\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        call = client.calls.create(\n",
        "            twiml=twiml_message,\n",
        "            to=guard_phone,\n",
        "            from_=TWILIO_NUMBER\n",
        "        )\n",
        "        print(f\"AI Alert call fired to {guard_name}\")\n",
        "        print(f\"Call SID: {call.sid}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Call failed: {e}\")\n",
        "        return False\n",
        "\n",
        "print(\"GenAI + Voice call connected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-LWawpK93Nu",
        "outputId": "53d4c503-7dbe-4765-98e3-2b4d0abf7c2b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenAI + Voice call connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backend"
      ],
      "metadata": {
        "id": "csnkQ2HkrQP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-cors pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HjdsE3RTVc0",
        "outputId": "27bde1cb-474a-4c65-c9c9-b39817d557f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.3)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initially run this once. And later if u wanted to try with new video run this and it clears the old paths, so from top run all cells again.\n",
        "# This is just to connect my local VsCode (frontend) with Colab (backend)\n",
        "# This cell prepares Colab backend for frontend connection\n",
        "import os\n",
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Safely free port 5050 (Colab/Linux)\n",
        "subprocess.run(\"fuser -k 5050/tcp\", shell=True, capture_output=True)\n",
        "\n",
        "# Read ngrok auth token from environment\n",
        "NGROK_AUTH_TOKEN = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "if not NGROK_AUTH_TOKEN:\n",
        "    raise ValueError(\"‚ùå NGROK_AUTH_TOKEN not set\")\n",
        "\n",
        "# Reset ngrok\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "print(\"‚úÖ Ngrok ready\")"
      ],
      "metadata": {
        "id": "L3THCadXYyO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b38c24-1a25-49ef-c1ee-86021bd78d62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ngrok ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CrowdPulse ‚Äî FINAL LIVE LOOP\n",
        "# Groq (Ideas 1, 2, 3) + Twilio + Flask API all in one cell\n",
        "# ============================================================\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# ‚îÄ‚îÄ GLOBAL STATE (must be before Flask) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "crowd_analysis = {}\n",
        "alerted_zones = {}\n",
        "incident_reports = []\n",
        "COOLDOWN_MINS = 5\n",
        "\n",
        "# ‚îÄ‚îÄ Flask API (starts in background) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "from flask import Flask, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route(\"/analysis\", methods=[\"GET\"])\n",
        "def get_analysis():\n",
        "    if crowd_analysis:\n",
        "        return jsonify(crowd_analysis)\n",
        "    return jsonify({\"message\": \"No analysis yet\"}), 204\n",
        "\n",
        "@app.route(\"/status\", methods=[\"GET\"])\n",
        "def get_status_api():\n",
        "    if json_outputs:\n",
        "        return jsonify(json_outputs[-1])\n",
        "    return jsonify({\"message\": \"No data yet\"}), 204\n",
        "\n",
        "@app.route(\"/health\", methods=[\"GET\"])\n",
        "def health():\n",
        "    return jsonify({\"status\": \"CrowdPulse running\"})\n",
        "\n",
        "@app.route(\"/reports\", methods=[\"GET\"])\n",
        "def get_reports():\n",
        "    return jsonify(incident_reports[-5:])\n",
        "\n",
        "def run_flask():\n",
        "    app.run(port=5050, use_reloader=False)\n",
        "\n",
        "threading.Thread(target=run_flask, daemon=True).start()\n",
        "public_url = ngrok.connect(5050)\n",
        "\n",
        "print(f\"‚úÖ API LIVE: {public_url}/status\")\n",
        "print(f\"üìã Reports: {public_url}/reports\")\n",
        "\n",
        "# ‚îÄ‚îÄ Helper: check cooldown ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def is_on_cooldown(zone):\n",
        "    last = alerted_zones.get(zone)\n",
        "    if not last:\n",
        "        return False\n",
        "    mins_since = (datetime.now() - last).seconds / 60\n",
        "    return mins_since < COOLDOWN_MINS\n",
        "\n",
        "# ‚îÄ‚îÄ Main alert handler ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "def handle_alert(zone, zone_data, full_json):\n",
        "\n",
        "    if is_on_cooldown(zone):\n",
        "        print(f\"  ‚è≥ {zone} on cooldown, skipping\")\n",
        "        return\n",
        "\n",
        "    guard = guards.get(zone)\n",
        "    if not guard:\n",
        "        print(f\"  ‚ö†Ô∏è No guard registered for {zone}\")\n",
        "        return\n",
        "\n",
        "    urgency = zone_data[\"status\"]\n",
        "    count   = zone_data[\"current_count\"]\n",
        "    mins    = zone_data[\"predicted_danger_in_mins\"]\n",
        "\n",
        "    safe_zones = {\n",
        "        \"Zone_A\": \"Zone_B\",\n",
        "        \"Zone_B\": \"Zone_A\",\n",
        "        \"Zone_C\": \"Zone_D\",\n",
        "        \"Zone_D\": \"Zone_C\"\n",
        "    }\n",
        "    safe_zone = safe_zones.get(zone, \"nearest exit\")\n",
        "\n",
        "    print(f\"\\n  üö® [{urgency}] {zone} ‚Äî calling {guard['name']}...\")\n",
        "\n",
        "    try:\n",
        "        ai_message = generate_alert_message(\n",
        "            zone=zone,\n",
        "            guard_name=guard[\"name\"],\n",
        "            current_count=int(count),\n",
        "            mins=mins,\n",
        "            safe_zone=safe_zone\n",
        "        )\n",
        "        print(f\"  ü§ñ Groq message: {ai_message[:80]}...\")\n",
        "    except Exception as e:\n",
        "        ai_message = (\n",
        "            f\"Alert for {guard['name']}. {urgency} in {zone}. \"\n",
        "            f\"{int(count)} people detected. Please respond immediately.\"\n",
        "        )\n",
        "        print(f\"  ‚ö†Ô∏è Groq failed, using fallback: {e}\")\n",
        "\n",
        "    try:\n",
        "        success = make_genai_alert_call(\n",
        "            zone=zone,\n",
        "            guard_name=guard[\"name\"],\n",
        "            guard_phone=guard[\"phone\"],\n",
        "            current_count=int(count),\n",
        "            mins=mins\n",
        "        )\n",
        "        if success:\n",
        "            alerted_zones[zone] = datetime.now()\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Alert call failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        report = generate_incident_report(full_json)\n",
        "        incident_reports.append({\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"zone\": zone,\n",
        "            \"urgency\": urgency,\n",
        "            \"report\": report\n",
        "        })\n",
        "        print(\"  üìã Incident report saved\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è Report generation failed: {e}\")\n",
        "\n",
        "# ‚îÄ‚îÄ MAIN VIDEO PROCESSING (RUN ONCE) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "for key in zone_history:\n",
        "    zone_history[key].clear()\n",
        "\n",
        "json_outputs = []\n",
        "frame_count = 0\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"CrowdPulse LIVE ‚Äî watching for danger...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "    if frame_count % 30 == 0:\n",
        "        zones_data = process_frame(frame)\n",
        "        frame = draw_zones_on_frame(frame, zones_data)\n",
        "\n",
        "        if all(len(h) >= 2 for h in zone_history.values()):\n",
        "            result = generate_alert_json(zone_history, zones_data)\n",
        "            json_outputs.append(result)\n",
        "\n",
        "            for alert in result[\"active_alerts\"]:\n",
        "                zone = alert[\"zone\"]\n",
        "                zone_data = result[\"zones\"][zone]\n",
        "                handle_alert(zone, zone_data, result)\n",
        "\n",
        "            clear_output(wait=True)\n",
        "            print(f\"‚úÖ API: {public_url}/status\")\n",
        "            print(\n",
        "                f\"Frame {frame_count} | \"\n",
        "                f\"Total: {result['total_count']} | \"\n",
        "                f\"Alerts: {len(result['active_alerts'])}\"\n",
        "            )\n",
        "\n",
        "            for z, d in result[\"zones\"].items():\n",
        "                status = d[\"status\"]\n",
        "                count  = int(d[\"current_count\"])\n",
        "                mins   = d[\"predicted_danger_in_mins\"]\n",
        "                icon = (\n",
        "                    \"üî¥\" if status in [\"DANGER\", \"CRITICAL\"]\n",
        "                    else \"üü°\" if status == \"WARNING\"\n",
        "                    else \"üü¢\"\n",
        "                )\n",
        "                print(\n",
        "                    f\"  {icon} {z}: {status} ({count} people)\"\n",
        "                    f\"{f' ‚Äî critical in {mins} min' if mins else ''}\"\n",
        "                )\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# ‚îÄ‚îÄ GROQ IDEA 2: END-OF-VIDEO ANALYSIS (ONCE) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "if json_outputs:\n",
        "    try:\n",
        "        analysis_text = generate_crowd_analysis(json_outputs[-20:])\n",
        "        crowd_analysis.update({\n",
        "            \"text\": analysis_text,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"snapshot_count\": len(json_outputs)\n",
        "        })\n",
        "        print(\"üìä Analysis saved!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Analysis failed: {e}\")\n",
        "\n",
        "print(\"‚úÖ Video processing complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "YnhUuhhgrOJH",
        "outputId": "1eec818b-49f5-4c59-fbf6-4c0655c873a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API: NgrokTunnel: \"https://sigrid-sirenic-uniridescently.ngrok-free.dev\" -> \"http://localhost:5050\"/status\n",
            "Frame 90 | Total: 22 | Alerts: 0\n",
            "  üü¢ Zone_A: SAFE (8 people) ‚Äî critical in 667.9 min\n",
            "  üü¢ Zone_B: SAFE (8 people)\n",
            "  üü¢ Zone_C: SAFE (1 people) ‚Äî critical in 426.5 min\n",
            "  üü¢ Zone_D: SAFE (3 people) ‚Äî critical in 199.0 min\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12317/1334645549.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mframe_count\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mzones_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_zones_on_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzones_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-12317/3360093160.py\u001b[0m in \u001b[0;36mprocess_frame\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mdensity_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensity_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-12317/2022818980.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrontend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \"\"\"\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    546\u001b[0m             )\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    549\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}